{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9235b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Episode: 1/500, Score: 15.0, Epsilon: 1.000\n",
      "Episode: 2/500, Score: 37.0, Epsilon: 0.905\n",
      "Episode: 2/500, Score: 37.0, Epsilon: 0.905\n",
      "Episode: 3/500, Score: 42.0, Epsilon: 0.737\n",
      "Episode: 3/500, Score: 42.0, Epsilon: 0.737\n",
      "Episode: 4/500, Score: 12.0, Epsilon: 0.697\n",
      "Episode: 4/500, Score: 12.0, Epsilon: 0.697\n",
      "Episode: 5/500, Score: 18.0, Epsilon: 0.640\n",
      "Episode: 5/500, Score: 18.0, Epsilon: 0.640\n",
      "Episode: 6/500, Score: 24.0, Epsilon: 0.570\n",
      "Episode: 6/500, Score: 24.0, Epsilon: 0.570\n",
      "Episode: 7/500, Score: 10.0, Epsilon: 0.545\n",
      "Episode: 7/500, Score: 10.0, Epsilon: 0.545\n",
      "Episode: 8/500, Score: 11.0, Epsilon: 0.519\n",
      "Episode: 8/500, Score: 11.0, Epsilon: 0.519\n",
      "Episode: 9/500, Score: 16.0, Epsilon: 0.481\n",
      "Episode: 9/500, Score: 16.0, Epsilon: 0.481\n",
      "Episode: 10/500, Score: 15.0, Epsilon: 0.448\n",
      "Episode: 10/500, Score: 15.0, Epsilon: 0.448\n",
      "Episode: 11/500, Score: 11.0, Epsilon: 0.427\n",
      "Episode: 11/500, Score: 11.0, Epsilon: 0.427\n",
      "Episode: 12/500, Score: 10.0, Epsilon: 0.408\n",
      "Episode: 12/500, Score: 10.0, Epsilon: 0.408\n",
      "Episode: 13/500, Score: 10.0, Epsilon: 0.390\n",
      "Episode: 13/500, Score: 10.0, Epsilon: 0.390\n",
      "Episode: 14/500, Score: 14.0, Epsilon: 0.365\n",
      "Episode: 14/500, Score: 14.0, Epsilon: 0.365\n",
      "Episode: 15/500, Score: 12.0, Epsilon: 0.346\n",
      "Episode: 15/500, Score: 12.0, Epsilon: 0.346\n",
      "Episode: 16/500, Score: 14.0, Epsilon: 0.324\n",
      "Episode: 16/500, Score: 14.0, Epsilon: 0.324\n",
      "Episode: 17/500, Score: 11.0, Epsilon: 0.308\n",
      "Episode: 17/500, Score: 11.0, Epsilon: 0.308\n",
      "Episode: 18/500, Score: 9.0, Epsilon: 0.296\n",
      "Episode: 18/500, Score: 9.0, Epsilon: 0.296\n",
      "Episode: 19/500, Score: 14.0, Epsilon: 0.277\n",
      "Episode: 19/500, Score: 14.0, Epsilon: 0.277\n",
      "Episode: 20/500, Score: 13.0, Epsilon: 0.261\n",
      "Episode: 20/500, Score: 13.0, Epsilon: 0.261\n",
      "Episode: 21/500, Score: 12.0, Epsilon: 0.247\n",
      "Episode: 21/500, Score: 12.0, Epsilon: 0.247\n",
      "Episode: 22/500, Score: 15.0, Epsilon: 0.230\n",
      "Episode: 22/500, Score: 15.0, Epsilon: 0.230\n",
      "Episode: 23/500, Score: 8.0, Epsilon: 0.222\n",
      "Episode: 23/500, Score: 8.0, Epsilon: 0.222\n",
      "Episode: 24/500, Score: 9.0, Epsilon: 0.214\n",
      "Episode: 24/500, Score: 9.0, Epsilon: 0.214\n",
      "Episode: 25/500, Score: 11.0, Epsilon: 0.203\n",
      "Episode: 25/500, Score: 11.0, Epsilon: 0.203\n",
      "Episode: 26/500, Score: 9.0, Epsilon: 0.195\n",
      "Episode: 26/500, Score: 9.0, Epsilon: 0.195\n",
      "Episode: 27/500, Score: 12.0, Epsilon: 0.185\n",
      "Episode: 27/500, Score: 12.0, Epsilon: 0.185\n",
      "Episode: 28/500, Score: 8.0, Epsilon: 0.178\n",
      "Episode: 28/500, Score: 8.0, Epsilon: 0.178\n",
      "Episode: 29/500, Score: 11.0, Epsilon: 0.170\n",
      "Episode: 29/500, Score: 11.0, Epsilon: 0.170\n",
      "Episode: 30/500, Score: 8.0, Epsilon: 0.164\n",
      "Episode: 30/500, Score: 8.0, Epsilon: 0.164\n",
      "Episode: 31/500, Score: 8.0, Epsilon: 0.158\n",
      "Episode: 31/500, Score: 8.0, Epsilon: 0.158\n",
      "Episode: 32/500, Score: 10.0, Epsilon: 0.151\n",
      "Episode: 32/500, Score: 10.0, Epsilon: 0.151\n",
      "Episode: 33/500, Score: 10.0, Epsilon: 0.144\n",
      "Episode: 33/500, Score: 10.0, Epsilon: 0.144\n",
      "Episode: 34/500, Score: 9.0, Epsilon: 0.139\n",
      "Episode: 34/500, Score: 9.0, Epsilon: 0.139\n",
      "Episode: 35/500, Score: 9.0, Epsilon: 0.133\n",
      "Episode: 35/500, Score: 9.0, Epsilon: 0.133\n",
      "Episode: 36/500, Score: 10.0, Epsilon: 0.127\n",
      "Episode: 36/500, Score: 10.0, Epsilon: 0.127\n",
      "Episode: 37/500, Score: 10.0, Epsilon: 0.122\n",
      "Episode: 37/500, Score: 10.0, Epsilon: 0.122\n",
      "Episode: 38/500, Score: 11.0, Epsilon: 0.116\n",
      "Episode: 38/500, Score: 11.0, Epsilon: 0.116\n",
      "Episode: 39/500, Score: 10.0, Epsilon: 0.111\n",
      "Episode: 39/500, Score: 10.0, Epsilon: 0.111\n",
      "Episode: 40/500, Score: 10.0, Epsilon: 0.106\n",
      "Episode: 40/500, Score: 10.0, Epsilon: 0.106\n",
      "Episode: 41/500, Score: 10.0, Epsilon: 0.101\n",
      "Episode: 41/500, Score: 10.0, Epsilon: 0.101\n",
      "Episode: 42/500, Score: 8.0, Epsilon: 0.098\n",
      "Episode: 42/500, Score: 8.0, Epsilon: 0.098\n",
      "Episode: 43/500, Score: 10.0, Epsilon: 0.093\n",
      "Episode: 43/500, Score: 10.0, Epsilon: 0.093\n",
      "Episode: 44/500, Score: 11.0, Epsilon: 0.089\n",
      "Episode: 44/500, Score: 11.0, Epsilon: 0.089\n",
      "Episode: 45/500, Score: 15.0, Epsilon: 0.083\n",
      "Episode: 45/500, Score: 15.0, Epsilon: 0.083\n",
      "Episode: 46/500, Score: 18.0, Epsilon: 0.076\n",
      "Episode: 46/500, Score: 18.0, Epsilon: 0.076\n",
      "Episode: 47/500, Score: 18.0, Epsilon: 0.070\n",
      "Episode: 47/500, Score: 18.0, Epsilon: 0.070\n",
      "Episode: 48/500, Score: 43.0, Epsilon: 0.057\n",
      "Episode: 48/500, Score: 43.0, Epsilon: 0.057\n",
      "Episode: 49/500, Score: 131.0, Epsilon: 0.029\n",
      "Episode: 49/500, Score: 131.0, Epsilon: 0.029\n",
      "Episode: 50/500, Score: 23.0, Epsilon: 0.026\n",
      "Episode: 50/500, Score: 23.0, Epsilon: 0.026\n",
      "Episode: 51/500, Score: 19.0, Epsilon: 0.024\n",
      "Episode: 51/500, Score: 19.0, Epsilon: 0.024\n",
      "Episode: 52/500, Score: 21.0, Epsilon: 0.022\n",
      "Episode: 52/500, Score: 21.0, Epsilon: 0.022\n",
      "Episode: 53/500, Score: 16.0, Epsilon: 0.020\n",
      "Episode: 53/500, Score: 16.0, Epsilon: 0.020\n",
      "Episode: 54/500, Score: 35.0, Epsilon: 0.017\n",
      "Episode: 54/500, Score: 35.0, Epsilon: 0.017\n",
      "Episode: 55/500, Score: 18.0, Epsilon: 0.016\n",
      "Episode: 55/500, Score: 18.0, Epsilon: 0.016\n",
      "Episode: 56/500, Score: 25.0, Epsilon: 0.014\n",
      "Episode: 56/500, Score: 25.0, Epsilon: 0.014\n",
      "Episode: 57/500, Score: 18.0, Epsilon: 0.013\n",
      "Episode: 57/500, Score: 18.0, Epsilon: 0.013\n",
      "Episode: 58/500, Score: 16.0, Epsilon: 0.012\n",
      "Episode: 58/500, Score: 16.0, Epsilon: 0.012\n",
      "Episode: 59/500, Score: 29.0, Epsilon: 0.010\n",
      "Episode: 59/500, Score: 29.0, Epsilon: 0.010\n",
      "Episode: 60/500, Score: 21.0, Epsilon: 0.010\n",
      "Episode: 60/500, Score: 21.0, Epsilon: 0.010\n",
      "Episode: 61/500, Score: 21.0, Epsilon: 0.010\n",
      "Episode: 61/500, Score: 21.0, Epsilon: 0.010\n",
      "Episode: 62/500, Score: 35.0, Epsilon: 0.010\n",
      "Episode: 62/500, Score: 35.0, Epsilon: 0.010\n",
      "Episode: 63/500, Score: 17.0, Epsilon: 0.010\n",
      "Episode: 63/500, Score: 17.0, Epsilon: 0.010\n",
      "Episode: 64/500, Score: 17.0, Epsilon: 0.010\n",
      "Episode: 64/500, Score: 17.0, Epsilon: 0.010\n",
      "Episode: 65/500, Score: 22.0, Epsilon: 0.010\n",
      "Episode: 65/500, Score: 22.0, Epsilon: 0.010\n",
      "Episode: 66/500, Score: 59.0, Epsilon: 0.010\n",
      "Episode: 66/500, Score: 59.0, Epsilon: 0.010\n",
      "Episode: 67/500, Score: 50.0, Epsilon: 0.010\n",
      "Episode: 67/500, Score: 50.0, Epsilon: 0.010\n",
      "Episode: 68/500, Score: 68.0, Epsilon: 0.010\n",
      "Episode: 68/500, Score: 68.0, Epsilon: 0.010\n",
      "Episode: 69/500, Score: 106.0, Epsilon: 0.010\n",
      "Episode: 69/500, Score: 106.0, Epsilon: 0.010\n",
      "Episode: 70/500, Score: 145.0, Epsilon: 0.010\n",
      "Episode: 70/500, Score: 145.0, Epsilon: 0.010\n",
      "Episode: 71/500, Score: 56.0, Epsilon: 0.010\n",
      "Episode: 71/500, Score: 56.0, Epsilon: 0.010\n",
      "Episode: 72/500, Score: 73.0, Epsilon: 0.010\n",
      "Episode: 72/500, Score: 73.0, Epsilon: 0.010\n",
      "Episode: 73/500, Score: 72.0, Epsilon: 0.010\n",
      "Episode: 73/500, Score: 72.0, Epsilon: 0.010\n",
      "Episode: 74/500, Score: 124.0, Epsilon: 0.010\n",
      "Episode: 74/500, Score: 124.0, Epsilon: 0.010\n",
      "Episode: 75/500, Score: 80.0, Epsilon: 0.010\n",
      "Episode: 75/500, Score: 80.0, Epsilon: 0.010\n",
      "Episode: 76/500, Score: 182.0, Epsilon: 0.010\n",
      "Episode: 76/500, Score: 182.0, Epsilon: 0.010\n",
      "Episode: 77/500, Score: 303.0, Epsilon: 0.010\n",
      "Episode: 77/500, Score: 303.0, Epsilon: 0.010\n",
      "Episode: 78/500, Score: 417.0, Epsilon: 0.010\n",
      "Episode: 78/500, Score: 417.0, Epsilon: 0.010\n",
      "Episode: 79/500, Score: 483.0, Epsilon: 0.010\n",
      "Episode: 79/500, Score: 483.0, Epsilon: 0.010\n",
      "Episode: 80/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 80/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 81/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 81/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 82/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 82/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 83/500, Score: 431.0, Epsilon: 0.010\n",
      "Episode: 83/500, Score: 431.0, Epsilon: 0.010\n",
      "Episode: 84/500, Score: 435.0, Epsilon: 0.010\n",
      "Episode: 84/500, Score: 435.0, Epsilon: 0.010\n",
      "Episode: 85/500, Score: 259.0, Epsilon: 0.010\n",
      "Episode: 85/500, Score: 259.0, Epsilon: 0.010\n",
      "Episode: 86/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 86/500, Score: 500.0, Epsilon: 0.010\n",
      "Episode: 87/500, Score: 282.0, Epsilon: 0.010\n",
      "Episode: 87/500, Score: 282.0, Epsilon: 0.010\n",
      "Episode: 88/500, Score: 380.0, Epsilon: 0.010\n",
      "Episode: 88/500, Score: 380.0, Epsilon: 0.010\n",
      "Episode: 89/500, Score: 265.0, Epsilon: 0.010\n",
      "Episode: 89/500, Score: 265.0, Epsilon: 0.010\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Epsilon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;241m.\u001b[39mepsilon\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m         \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 65\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(actions):\n\u001b[1;32m     63\u001b[0m     target_f[i][action] \u001b[38;5;241m=\u001b[39m targets[i]\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_min:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_decay\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:338\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    331\u001b[0m     (\n\u001b[1;32m    332\u001b[0m         val_x,\n\u001b[1;32m    333\u001b[0m         val_y,\n\u001b[1;32m    334\u001b[0m         val_sample_weight,\n\u001b[1;32m    335\u001b[0m     ) \u001b[38;5;241m=\u001b[39m data_adapter_utils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# Create an iterator that yields batches for one epoch.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_symbolic_build(iterator\u001b[38;5;241m=\u001b[39mepoch_iterator)\n\u001b[1;32m    351\u001b[0m epoch_iterator\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:726\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[0;32m--> 726\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[1;32m    728\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[1;32m    729\u001b[0m         dataset\n\u001b[1;32m    730\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:231\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mwith_options(options)\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m--> 231\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    233\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2389\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[1;32m   2386\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2388\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[0;32m-> 2389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py:33\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m---> 33\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, dataset_ops\u001b[38;5;241m.\u001b[39mDatasetSpec):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_ops\u001b[38;5;241m.\u001b[39mget_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1256\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1255\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1257\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1226\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1230\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1065\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n\u001b[0;32m-> 1065\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# flatten and unflatten func_args and func_kwargs to maintain parity\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# from flattening which sorts by key\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m func_args \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   1071\u001b[0m     func_args,\n\u001b[1;32m   1072\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(func_args, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   1073\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:628\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    544\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:1065\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1065\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1067\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:1103\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1101\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:903\u001b[0m, in \u001b[0;36m_tf_core_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    900\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_sequence[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 903\u001b[0m   final_index, packed \u001b[38;5;241m=\u001b[39m \u001b[43m_tf_core_packed_nest_with_indices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_nested_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_fn\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m final_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(flat_sequence):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ITC/FinSearch-Deep-RL/.conda/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:571\u001b[0m, in \u001b[0;36m_tf_core_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_nested_fn, sequence_fn)\u001b[0m\n\u001b[1;32m    569\u001b[0m packed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    570\u001b[0m sequence_fn \u001b[38;5;241m=\u001b[39m sequence_fn \u001b[38;5;129;01mor\u001b[39;00m sequence_like\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m _tf_core_yield_value(structure):\n\u001b[1;32m    572\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_nested_fn(s):\n\u001b[1;32m    573\u001b[0m     new_index, child \u001b[38;5;241m=\u001b[39m _tf_core_packed_nest_with_indices(\n\u001b[1;32m    574\u001b[0m         s, flat, index, is_nested_fn, sequence_fn\n\u001b[1;32m    575\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Force CPU usage to avoid GPU driver issues\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Define the DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([e[0][0] for e in minibatch])\n",
    "        actions = np.array([e[1] for e in minibatch])\n",
    "        rewards = np.array([e[2] for e in minibatch])\n",
    "        next_states = np.array([e[3][0] for e in minibatch])\n",
    "        dones = np.array([e[4] for e in minibatch])\n",
    "\n",
    "        targets = rewards + (1 - dones) * self.gamma * np.max(self.model.predict(next_states, verbose=0), axis=1)\n",
    "        target_f = self.model.predict(states, verbose=0)\n",
    "        \n",
    "        for i, action in enumerate(actions):\n",
    "            target_f[i][action] = targets[i]\n",
    "        \n",
    "        self.model.fit(states, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Initialize and train\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "episodes = 500  # Reduced for faster testing\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    if isinstance(state, tuple):  # Handle newer gym versions\n",
    "        state = state[0]\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    \n",
    "    total_reward = 0\n",
    "    for time in range(500):\n",
    "        action = agent.act(state)\n",
    "        step_result = env.step(action)\n",
    "        \n",
    "        if len(step_result) == 5:  # Newer gym version\n",
    "            next_state, reward, done, truncated, _ = step_result\n",
    "            done = done or truncated\n",
    "        else:  # Older gym version\n",
    "            next_state, reward, done, _ = step_result\n",
    "            \n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Episode: {e+1}/{episodes}, Score: {total_reward}, Epsilon: {agent.epsilon:.3f}\")\n",
    "            break\n",
    "            \n",
    "        agent.replay(batch_size)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained agent\n",
    "def test_agent(agent, env, num_episodes=5):\n",
    "    \"\"\"Test the trained agent and optionally render the environment\"\"\"\n",
    "    test_scores = []\n",
    "    \n",
    "    # Set epsilon to 0 for pure exploitation (no random actions)\n",
    "    original_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTING TRAINED AGENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "        state = np.reshape(state, [1, agent.state_size])\n",
    "        \n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        \n",
    "        for time in range(500):  # Max 500 steps per episode\n",
    "            action = agent.act(state)  # Pure exploitation\n",
    "            step_result = env.step(action)\n",
    "            \n",
    "            if len(step_result) == 5:\n",
    "                next_state, reward, done, truncated, _ = step_result\n",
    "                done = done or truncated\n",
    "            else:\n",
    "                next_state, reward, done, _ = step_result\n",
    "            \n",
    "            state = np.reshape(next_state, [1, agent.state_size])\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        test_scores.append(total_reward)\n",
    "        print(f\"Test Episode {episode + 1}: Score = {total_reward} (survived {steps} steps)\")\n",
    "    \n",
    "    # Restore original epsilon\n",
    "    agent.epsilon = original_epsilon\n",
    "    \n",
    "    avg_score = np.mean(test_scores)\n",
    "    print(f\"\\nAverage Test Score: {avg_score:.2f}\")\n",
    "    print(f\"Best Test Score: {max(test_scores)}\")\n",
    "    print(f\"Worst Test Score: {min(test_scores)}\")\n",
    "    \n",
    "    return test_scores\n",
    "\n",
    "# Create a visual environment for demonstration\n",
    "def demonstrate_agent(agent, num_episodes=3):\n",
    "    \"\"\"Visually demonstrate the trained agent\"\"\"\n",
    "    # Create environment with rendering\n",
    "    visual_env = gym.make('CartPole-v1', render_mode='human')\n",
    "    \n",
    "    # Set epsilon to 0 for pure exploitation\n",
    "    original_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VISUAL DEMONSTRATION - Watch the CartPole!\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Close the window to continue to next episode...\")\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = visual_env.reset()\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "        state = np.reshape(state, [1, agent.state_size])\n",
    "        \n",
    "        total_reward = 0\n",
    "        \n",
    "        for time in range(500):\n",
    "            visual_env.render()  # Show the environment\n",
    "            action = agent.act(state)\n",
    "            step_result = visual_env.step(action)\n",
    "            \n",
    "            if len(step_result) == 5:\n",
    "                next_state, reward, done, truncated, _ = step_result\n",
    "                done = done or truncated\n",
    "            else:\n",
    "                next_state, reward, done, _ = step_result\n",
    "            \n",
    "            state = np.reshape(next_state, [1, agent.state_size])\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                print(f\"Visual Demo Episode {episode + 1}: Score = {total_reward}\")\n",
    "                break\n",
    "        \n",
    "        # Small delay between episodes\n",
    "        import time\n",
    "        time.sleep(2)\n",
    "    \n",
    "    visual_env.close()\n",
    "    agent.epsilon = original_epsilon\n",
    "    print(\"Visual demonstration completed!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Running numerical tests first...\")\n",
    "test_scores = test_agent(agent, env, num_episodes=5)\n",
    "\n",
    "print(\"\\nStarting visual demonstration...\")\n",
    "demonstrate_agent(agent, num_episodes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23920e",
   "metadata": {},
   "source": [
    "## Explanation of the DQN Implementation\n",
    "\n",
    "1. **Environment Setup**: The `CartPole-v1` environment from OpenAI Gym is used to simulate the inverted pendulum problem. The goal is to balance a pole on a cart by applying forces to the cart.\n",
    "\n",
    "2. **DQN Agent**:\n",
    "   - The agent is defined with a neural network model that approximates the Q-function.\n",
    "   - The model has three layers: two hidden layers with 24 neurons each and ReLU activation, and an output layer with linear activation.\n",
    "   - The agent uses an epsilon-greedy policy for exploration and exploitation.\n",
    "\n",
    "3. **Experience Replay**:\n",
    "   - The agent stores past experiences in a replay buffer.\n",
    "   - During training, random batches are sampled from the buffer to update the Q-values, improving stability and efficiency.\n",
    "\n",
    "4. **Training Loop**:\n",
    "   - For each episode, the agent interacts with the environment, selects actions, and stores experiences.\n",
    "   - The agent trains on batches of experiences from the replay buffer to update its Q-function.\n",
    "   - The exploration rate (`epsilon`) decays over time to shift from exploration to exploitation.\n",
    "\n",
    "5. **Performance Metrics**:\n",
    "   - The score for each episode is printed, along with the current exploration rate.\n",
    "   - The training continues for 1000 episodes or until the agent achieves satisfactory performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
